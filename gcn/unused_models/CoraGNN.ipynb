{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/em/anaconda3/envs/venv/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading corafrom https://github.com/tkipf/gcn/raw/master/gcn/data/\n",
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "from spektral.datasets import citation\n",
    "data = citation.load_data('cora')\n",
    "A, X, y, train_mask, val_mask, test_mask = data\n",
    "\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 09:57:18.131289 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0909 09:57:18.142784 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0909 09:57:18.144531 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:539: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "W0909 09:57:18.148360 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0909 09:57:18.164442 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1133: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "W0909 09:57:18.176412 4398224832 deprecation.py:506] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "X_in = Input(shape=(F, ))  # Input layer for X\n",
    "A_in = Input((N, ), sparse=True)  # Input layer for A\n",
    "\n",
    "graph_conv_1 = GraphConv(16, activation='relu')([X_in, A_in])\n",
    "dropout = Dropout(0.5)(graph_conv_1)\n",
    "graph_conv_2 = GraphConv(n_classes, activation='softmax')([dropout, A_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=graph_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral import utils\n",
    "A = utils.localpooling_filter(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 09:57:31.849871 4398224832 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2708)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 16)           22944       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_2 (GraphConv)        (None, 7)            119         dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 09:57:39.265661 4398224832 deprecation.py:323] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2708 samples, validate on 2708 samples\n",
      "Epoch 1/100\n",
      "2708/2708 [==============================] - 0s 120us/step - loss: 1.9460 - weighted_acc: 0.1643 - val_loss: 1.9463 - val_weighted_acc: 0.1220\n",
      "Epoch 2/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9452 - weighted_acc: 0.1643 - val_loss: 1.9457 - val_weighted_acc: 0.1620\n",
      "Epoch 3/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9445 - weighted_acc: 0.1357 - val_loss: 1.9450 - val_weighted_acc: 0.2180\n",
      "Epoch 4/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9436 - weighted_acc: 0.2357 - val_loss: 1.9445 - val_weighted_acc: 0.2360\n",
      "Epoch 5/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9426 - weighted_acc: 0.3071 - val_loss: 1.9440 - val_weighted_acc: 0.2640\n",
      "Epoch 6/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9417 - weighted_acc: 0.3643 - val_loss: 1.9435 - val_weighted_acc: 0.3040\n",
      "Epoch 7/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9403 - weighted_acc: 0.3429 - val_loss: 1.9430 - val_weighted_acc: 0.3440\n",
      "Epoch 8/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9400 - weighted_acc: 0.4357 - val_loss: 1.9426 - val_weighted_acc: 0.3780\n",
      "Epoch 9/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9390 - weighted_acc: 0.4000 - val_loss: 1.9420 - val_weighted_acc: 0.4080\n",
      "Epoch 10/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9377 - weighted_acc: 0.4286 - val_loss: 1.9415 - val_weighted_acc: 0.4260\n",
      "Epoch 11/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9368 - weighted_acc: 0.4643 - val_loss: 1.9410 - val_weighted_acc: 0.4260\n",
      "Epoch 12/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9357 - weighted_acc: 0.4429 - val_loss: 1.9404 - val_weighted_acc: 0.4160\n",
      "Epoch 13/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9353 - weighted_acc: 0.5000 - val_loss: 1.9397 - val_weighted_acc: 0.4160\n",
      "Epoch 14/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9351 - weighted_acc: 0.3714 - val_loss: 1.9391 - val_weighted_acc: 0.4140\n",
      "Epoch 15/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9327 - weighted_acc: 0.5000 - val_loss: 1.9384 - val_weighted_acc: 0.4180\n",
      "Epoch 16/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9318 - weighted_acc: 0.4857 - val_loss: 1.9377 - val_weighted_acc: 0.4220\n",
      "Epoch 17/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9299 - weighted_acc: 0.4643 - val_loss: 1.9371 - val_weighted_acc: 0.4160\n",
      "Epoch 18/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9294 - weighted_acc: 0.4500 - val_loss: 1.9364 - val_weighted_acc: 0.4200\n",
      "Epoch 19/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9288 - weighted_acc: 0.5000 - val_loss: 1.9356 - val_weighted_acc: 0.4200\n",
      "Epoch 20/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9256 - weighted_acc: 0.5071 - val_loss: 1.9349 - val_weighted_acc: 0.4260\n",
      "Epoch 21/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9258 - weighted_acc: 0.5214 - val_loss: 1.9341 - val_weighted_acc: 0.4300\n",
      "Epoch 22/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9237 - weighted_acc: 0.5643 - val_loss: 1.9333 - val_weighted_acc: 0.4420\n",
      "Epoch 23/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9238 - weighted_acc: 0.5429 - val_loss: 1.9325 - val_weighted_acc: 0.4520\n",
      "Epoch 24/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9224 - weighted_acc: 0.5643 - val_loss: 1.9317 - val_weighted_acc: 0.4560\n",
      "Epoch 25/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9194 - weighted_acc: 0.5857 - val_loss: 1.9310 - val_weighted_acc: 0.4700\n",
      "Epoch 26/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9191 - weighted_acc: 0.6000 - val_loss: 1.9303 - val_weighted_acc: 0.4920\n",
      "Epoch 27/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9177 - weighted_acc: 0.6071 - val_loss: 1.9295 - val_weighted_acc: 0.5040\n",
      "Epoch 28/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9158 - weighted_acc: 0.6143 - val_loss: 1.9288 - val_weighted_acc: 0.5120\n",
      "Epoch 29/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9138 - weighted_acc: 0.6071 - val_loss: 1.9281 - val_weighted_acc: 0.5280\n",
      "Epoch 30/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9142 - weighted_acc: 0.6500 - val_loss: 1.9274 - val_weighted_acc: 0.5400\n",
      "Epoch 31/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9136 - weighted_acc: 0.6429 - val_loss: 1.9267 - val_weighted_acc: 0.5540\n",
      "Epoch 32/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9107 - weighted_acc: 0.7071 - val_loss: 1.9259 - val_weighted_acc: 0.5660\n",
      "Epoch 33/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9082 - weighted_acc: 0.7571 - val_loss: 1.9252 - val_weighted_acc: 0.5700\n",
      "Epoch 34/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9069 - weighted_acc: 0.7214 - val_loss: 1.9245 - val_weighted_acc: 0.5800\n",
      "Epoch 35/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9055 - weighted_acc: 0.7357 - val_loss: 1.9237 - val_weighted_acc: 0.5800\n",
      "Epoch 36/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9044 - weighted_acc: 0.7214 - val_loss: 1.9230 - val_weighted_acc: 0.5820\n",
      "Epoch 37/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9030 - weighted_acc: 0.7143 - val_loss: 1.9222 - val_weighted_acc: 0.5940\n",
      "Epoch 38/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.9011 - weighted_acc: 0.7214 - val_loss: 1.9214 - val_weighted_acc: 0.5960\n",
      "Epoch 39/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8991 - weighted_acc: 0.7500 - val_loss: 1.9205 - val_weighted_acc: 0.5980\n",
      "Epoch 40/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8970 - weighted_acc: 0.7857 - val_loss: 1.9197 - val_weighted_acc: 0.6040\n",
      "Epoch 41/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8961 - weighted_acc: 0.7429 - val_loss: 1.9188 - val_weighted_acc: 0.6060\n",
      "Epoch 42/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8948 - weighted_acc: 0.7357 - val_loss: 1.9179 - val_weighted_acc: 0.6080\n",
      "Epoch 43/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8926 - weighted_acc: 0.7571 - val_loss: 1.9169 - val_weighted_acc: 0.6100\n",
      "Epoch 44/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8934 - weighted_acc: 0.7286 - val_loss: 1.9160 - val_weighted_acc: 0.6140\n",
      "Epoch 45/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8920 - weighted_acc: 0.7357 - val_loss: 1.9151 - val_weighted_acc: 0.6160\n",
      "Epoch 46/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8882 - weighted_acc: 0.7571 - val_loss: 1.9142 - val_weighted_acc: 0.6180\n",
      "Epoch 47/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8897 - weighted_acc: 0.7357 - val_loss: 1.9133 - val_weighted_acc: 0.6160\n",
      "Epoch 48/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8864 - weighted_acc: 0.7571 - val_loss: 1.9123 - val_weighted_acc: 0.6200\n",
      "Epoch 49/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8822 - weighted_acc: 0.7714 - val_loss: 1.9114 - val_weighted_acc: 0.6200\n",
      "Epoch 50/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8787 - weighted_acc: 0.8071 - val_loss: 1.9105 - val_weighted_acc: 0.6200\n",
      "Epoch 51/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8764 - weighted_acc: 0.7500 - val_loss: 1.9097 - val_weighted_acc: 0.6220\n",
      "Epoch 52/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8782 - weighted_acc: 0.7929 - val_loss: 1.9088 - val_weighted_acc: 0.6260\n",
      "Epoch 53/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8767 - weighted_acc: 0.8000 - val_loss: 1.9080 - val_weighted_acc: 0.6220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8758 - weighted_acc: 0.7857 - val_loss: 1.9072 - val_weighted_acc: 0.6200\n",
      "Epoch 55/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8705 - weighted_acc: 0.7786 - val_loss: 1.9063 - val_weighted_acc: 0.6160\n",
      "Epoch 56/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8713 - weighted_acc: 0.8143 - val_loss: 1.9054 - val_weighted_acc: 0.6160\n",
      "Epoch 57/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8707 - weighted_acc: 0.8000 - val_loss: 1.9045 - val_weighted_acc: 0.6180\n",
      "Epoch 58/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8669 - weighted_acc: 0.7571 - val_loss: 1.9035 - val_weighted_acc: 0.6200\n",
      "Epoch 59/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8628 - weighted_acc: 0.8214 - val_loss: 1.9025 - val_weighted_acc: 0.6220\n",
      "Epoch 60/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8655 - weighted_acc: 0.8071 - val_loss: 1.9015 - val_weighted_acc: 0.6240\n",
      "Epoch 61/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8636 - weighted_acc: 0.7929 - val_loss: 1.9005 - val_weighted_acc: 0.6280\n",
      "Epoch 62/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8637 - weighted_acc: 0.7214 - val_loss: 1.8994 - val_weighted_acc: 0.6280\n",
      "Epoch 63/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8585 - weighted_acc: 0.8143 - val_loss: 1.8983 - val_weighted_acc: 0.6340\n",
      "Epoch 64/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8532 - weighted_acc: 0.8000 - val_loss: 1.8972 - val_weighted_acc: 0.6380\n",
      "Epoch 65/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8537 - weighted_acc: 0.8071 - val_loss: 1.8961 - val_weighted_acc: 0.6400\n",
      "Epoch 66/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8484 - weighted_acc: 0.7857 - val_loss: 1.8951 - val_weighted_acc: 0.6420\n",
      "Epoch 67/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8484 - weighted_acc: 0.8143 - val_loss: 1.8940 - val_weighted_acc: 0.6440\n",
      "Epoch 68/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8475 - weighted_acc: 0.8143 - val_loss: 1.8929 - val_weighted_acc: 0.6440\n",
      "Epoch 69/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8483 - weighted_acc: 0.8000 - val_loss: 1.8918 - val_weighted_acc: 0.6440\n",
      "Epoch 70/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8468 - weighted_acc: 0.8357 - val_loss: 1.8908 - val_weighted_acc: 0.6400\n",
      "Epoch 71/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8466 - weighted_acc: 0.7929 - val_loss: 1.8897 - val_weighted_acc: 0.6420\n",
      "Epoch 72/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8414 - weighted_acc: 0.7500 - val_loss: 1.8887 - val_weighted_acc: 0.6420\n",
      "Epoch 73/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8405 - weighted_acc: 0.7929 - val_loss: 1.8876 - val_weighted_acc: 0.6440\n",
      "Epoch 74/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8378 - weighted_acc: 0.8500 - val_loss: 1.8865 - val_weighted_acc: 0.6520\n",
      "Epoch 75/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8367 - weighted_acc: 0.8000 - val_loss: 1.8855 - val_weighted_acc: 0.6500\n",
      "Epoch 76/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8378 - weighted_acc: 0.7929 - val_loss: 1.8845 - val_weighted_acc: 0.6520\n",
      "Epoch 77/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8281 - weighted_acc: 0.8500 - val_loss: 1.8834 - val_weighted_acc: 0.6540\n",
      "Epoch 78/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8340 - weighted_acc: 0.7643 - val_loss: 1.8824 - val_weighted_acc: 0.6540\n",
      "Epoch 79/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8301 - weighted_acc: 0.8143 - val_loss: 1.8813 - val_weighted_acc: 0.6560\n",
      "Epoch 80/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8276 - weighted_acc: 0.7786 - val_loss: 1.8802 - val_weighted_acc: 0.6600\n",
      "Epoch 81/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8260 - weighted_acc: 0.8429 - val_loss: 1.8790 - val_weighted_acc: 0.6620\n",
      "Epoch 82/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8229 - weighted_acc: 0.8071 - val_loss: 1.8779 - val_weighted_acc: 0.6620\n",
      "Epoch 83/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8233 - weighted_acc: 0.8000 - val_loss: 1.8767 - val_weighted_acc: 0.6640\n",
      "Epoch 84/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8175 - weighted_acc: 0.8429 - val_loss: 1.8756 - val_weighted_acc: 0.6640\n",
      "Epoch 85/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8147 - weighted_acc: 0.8143 - val_loss: 1.8744 - val_weighted_acc: 0.6640\n",
      "Epoch 86/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8183 - weighted_acc: 0.7929 - val_loss: 1.8732 - val_weighted_acc: 0.6640\n",
      "Epoch 87/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8139 - weighted_acc: 0.8429 - val_loss: 1.8720 - val_weighted_acc: 0.6640\n",
      "Epoch 88/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8082 - weighted_acc: 0.8571 - val_loss: 1.8709 - val_weighted_acc: 0.6640\n",
      "Epoch 89/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8048 - weighted_acc: 0.8286 - val_loss: 1.8697 - val_weighted_acc: 0.6660\n",
      "Epoch 90/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8075 - weighted_acc: 0.8143 - val_loss: 1.8687 - val_weighted_acc: 0.6640\n",
      "Epoch 91/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8007 - weighted_acc: 0.8071 - val_loss: 1.8676 - val_weighted_acc: 0.6620\n",
      "Epoch 92/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.8005 - weighted_acc: 0.8643 - val_loss: 1.8665 - val_weighted_acc: 0.6580\n",
      "Epoch 93/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7976 - weighted_acc: 0.8214 - val_loss: 1.8654 - val_weighted_acc: 0.6580\n",
      "Epoch 94/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7964 - weighted_acc: 0.8357 - val_loss: 1.8641 - val_weighted_acc: 0.6580\n",
      "Epoch 95/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7931 - weighted_acc: 0.8214 - val_loss: 1.8628 - val_weighted_acc: 0.6580\n",
      "Epoch 96/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7871 - weighted_acc: 0.8571 - val_loss: 1.8616 - val_weighted_acc: 0.6580\n",
      "Epoch 97/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7927 - weighted_acc: 0.8500 - val_loss: 1.8604 - val_weighted_acc: 0.6600\n",
      "Epoch 98/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7872 - weighted_acc: 0.9143 - val_loss: 1.8592 - val_weighted_acc: 0.6620\n",
      "Epoch 99/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7830 - weighted_acc: 0.8071 - val_loss: 1.8580 - val_weighted_acc: 0.6640\n",
      "Epoch 100/100\n",
      "2708/2708 [==============================] - 0s 8us/step - loss: 1.7854 - weighted_acc: 0.8214 - val_loss: 1.8567 - val_weighted_acc: 0.6680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a308fbb50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "validation_data = ([X, A], y, val_mask)\n",
    "model.fit([X, A],\n",
    "          y,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=100,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False)  # Shuffling data means shuffling the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708/2708 [==============================] - 0s 3us/step\n",
      "Done.\n",
      "Test loss: 1.8536092042922974\n",
      "Test accuracy: 0.6829991936683655\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = model.evaluate([X, A],\n",
    "                              y,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
