{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/em/anaconda3/envs/venv/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.backend import mean, square\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot\n",
    "\n",
    "from os import path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [00:32<00:00, 4074.36it/s]\n"
     ]
    }
   ],
   "source": [
    "A_complete, X_complete, E_complete, y_complete = qm9.load_data(return_type='numpy',\n",
    "                           nf_keys='atomic_num',\n",
    "                           ef_keys='type',\n",
    "                           self_loops=True,\n",
    "                           amount=None)  # Set to None to train on whole dataset\n",
    "# one-hot labeling of atoms\n",
    "uniq_X = np.unique(X_complete)\n",
    "X_complete = label_to_one_hot(X_complete, uniq_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, X, E = list(), list(), list()\n",
    "y = y_complete.sample(10000)\n",
    "for index, row in y.iterrows():\n",
    "    A.append(A_complete[index])\n",
    "    X.append(X_complete[index])\n",
    "    E.append(E_complete[index])\n",
    "A = np.stack(A, axis=0)\n",
    "X = np.stack(X, axis=0)\n",
    "E = np.stack(E, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = list(y.columns)[1:]\n",
    "y_list = []\n",
    "for task in tasks:\n",
    "    y_list.append(y[[task]].values)\n",
    "for i in range(len(y_list)):\n",
    "    y_list[i] = StandardScaler().fit_transform(y_list[i]).reshape(-1, y_list[0].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[-2]\n",
    "F = X.shape[-1] \n",
    "S = E.shape[-1]\n",
    "n_out = y_list[0].shape[-1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "es_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learning_rate)\n",
    "loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, \\\n",
    "X_train, X_test, \\\n",
    "E_train, E_test, \\\n",
    "*y_train_test_list = train_test_split(A, X, E, *y_list, test_size = 0.1)\n",
    "\n",
    "y_train_list = y_train_test_list[::2]\n",
    "y_test_list = y_train_test_list[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1215 22:11:03.302671 4754589120 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1215 22:11:03.303588 4754589120 deprecation_wrapper.py:119] From /Users/em/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(N, F))\n",
    "A_in = Input(shape=(N, N))\n",
    "E_in = Input(shape=(N, N, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_task_model(X_in, A_in, E_in):\n",
    "    gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "    gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "    pool = GlobalAttentionPool(256)(gc2)\n",
    "    dense1 = Dense(256, activation='relu')(pool)\n",
    "    output = Dense(n_out)(dense1)\n",
    "    return Model(inputs=[X_in, A_in, E_in], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(task):\n",
    "    return path.join('gcnmodels', task + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'u0', 'u298', 'h298', 'g298', 'cv', 'u0_atom', 'u298_atom', 'h298_atom', 'g298_atom']\n"
     ]
    }
   ],
   "source": [
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning A\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.2603 - val_loss: 8.5762\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.2514 - val_loss: 8.5817\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.2487 - val_loss: 8.5866\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.2485 - val_loss: 8.5739\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2483 - val_loss: 8.5737\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.2482 - val_loss: 8.5688\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2478 - val_loss: 8.5720\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2469 - val_loss: 8.5779\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2473 - val_loss: 8.5760\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.2463 - val_loss: 8.5783\n",
      "learning B\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.5724 - val_loss: 4.8090\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.4526 - val_loss: 3.8033\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.3950 - val_loss: 3.6516\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.3770 - val_loss: 3.7231\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.3464 - val_loss: 3.6009\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3241 - val_loss: 3.4422\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3111 - val_loss: 3.3405\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.2930 - val_loss: 3.3783\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2886 - val_loss: 3.0091\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.2690 - val_loss: 3.2776\n",
      "learning C\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.4485 - val_loss: 6.0023\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3775 - val_loss: 5.4136\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3032 - val_loss: 4.8742\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3177 - val_loss: 4.8008\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2511 - val_loss: 4.6698\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2327 - val_loss: 4.6816\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2057 - val_loss: 4.6661\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1944 - val_loss: 4.5201\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.1982 - val_loss: 4.4937\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 44s 5ms/step - loss: 0.1837 - val_loss: 4.5007\n",
      "learning mu\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.6800 - val_loss: 0.5489\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 44s 5ms/step - loss: 0.6008 - val_loss: 0.5360\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 44s 5ms/step - loss: 0.5808 - val_loss: 0.5439\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 44s 5ms/step - loss: 0.5837 - val_loss: 0.5642\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.5775 - val_loss: 0.5420\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.5739 - val_loss: 0.5550\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.5675 - val_loss: 0.5323\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.5630 - val_loss: 0.5174\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.5558 - val_loss: 0.5252\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.5518 - val_loss: 0.5193\n",
      "learning homo\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.8120 - val_loss: 0.6104\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.5669 - val_loss: 0.5497\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.4787 - val_loss: 0.4556\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.4452 - val_loss: 0.4377\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.4261 - val_loss: 0.4251\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.4076 - val_loss: 0.3983\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.3865 - val_loss: 0.4096\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.3874 - val_loss: 0.3841\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.3769 - val_loss: 0.3776\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 53s 7ms/step - loss: 0.3789 - val_loss: 0.3861\n",
      "learning lumo\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.5876 - val_loss: 0.2885\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2865 - val_loss: 0.2361\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2284 - val_loss: 0.1781\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.2068 - val_loss: 0.1656\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1949 - val_loss: 0.1513\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1778 - val_loss: 0.1315\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1730 - val_loss: 0.1734\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.1614 - val_loss: 0.1274\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.1558 - val_loss: 0.1199\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.1512 - val_loss: 0.1149\n",
      "learning gap\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 52s 6ms/step - loss: 0.5526 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2812 - val_loss: 0.2810\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2279 - val_loss: 0.1883\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2218 - val_loss: 0.1826\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2045 - val_loss: 0.1754\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2014 - val_loss: 0.1730\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.1960 - val_loss: 0.1605\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.1897 - val_loss: 0.1547\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1905 - val_loss: 0.1586\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.1812 - val_loss: 0.1616\n",
      "learning zpve\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.4523 - val_loss: 0.2935\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.2482 - val_loss: 0.1570\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.1153 - val_loss: 0.0925\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0766 - val_loss: 0.0882\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0672 - val_loss: 0.0592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.0712 - val_loss: 0.0636\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0610 - val_loss: 0.0513\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0535 - val_loss: 0.0510\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0493 - val_loss: 0.0466\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0493 - val_loss: 0.0587\n",
      "learning u0\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.4434 - val_loss: 0.2202\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0724 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0214 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 51s 6ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "learning u298\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 52s 6ms/step - loss: 0.2135 - val_loss: 0.0287\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.0243 - val_loss: 0.0139\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0074 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 50s 6ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "learning h298\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.2704 - val_loss: 0.0348\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0280 - val_loss: 0.0204\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0048 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "learning g298\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.2854 - val_loss: 0.0321\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0203 - val_loss: 0.0111\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 17073s 2s/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 26203s 3s/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 14563s 2s/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 49s 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "learning cv\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.9103 - val_loss: 0.8704\n",
      "Epoch 2/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.6290 - val_loss: 0.3772\n",
      "Epoch 3/10\n",
      "8100/8100 [==============================] - 47s 6ms/step - loss: 0.2645 - val_loss: 0.1518\n",
      "Epoch 4/10\n",
      "8100/8100 [==============================] - 45s 5ms/step - loss: 0.1341 - val_loss: 0.1330\n",
      "Epoch 5/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.1064 - val_loss: 0.1158\n",
      "Epoch 6/10\n",
      "8100/8100 [==============================] - 46s 6ms/step - loss: 0.0845 - val_loss: 0.1165\n",
      "Epoch 7/10\n",
      "8100/8100 [==============================] - 48s 6ms/step - loss: 0.0848 - val_loss: 0.1333\n",
      "Epoch 8/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0719 - val_loss: 0.0648\n",
      "Epoch 9/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0741 - val_loss: 0.1203\n",
      "Epoch 10/10\n",
      "8100/8100 [==============================] - 45s 6ms/step - loss: 0.0720 - val_loss: 0.0557\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 15):\n",
    "    if i == 4:\n",
    "        continue\n",
    "    if i == 8:\n",
    "        continue\n",
    "    print('learning', tasks[i])\n",
    "    model = create_single_task_model(X_in, A_in, E_in)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)\n",
    "    model.fit([X_train, A_train, E_train],\n",
    "             y_train_list[i],\n",
    "             batch_size=batch_size,\n",
    "             validation_split=0.1,\n",
    "             epochs=epochs,\n",
    "             callbacks=[es_callback])\n",
    "    model.save_weights(generate_filename(tasks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
