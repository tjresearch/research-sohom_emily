{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run QM9GNN2_Multitask.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learning_rate)\n",
    "loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_task_filename(task):\n",
    "    return path.join('single_task_trained_models', task + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_single_task_model(*, N, F, S):\n",
    "  X_in = Input(shape=(N, F))\n",
    "  A_in = Input(shape=(N, N))\n",
    "  E_in = Input(shape=(N, N, S))\n",
    "\n",
    "  gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "  gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "  pool = GlobalAttentionPool(256)(gc2)\n",
    "  dense = Dense(256, activation='relu')(pool)\n",
    "  output = Dense(1)(dense)\n",
    "\n",
    "  # Build model\n",
    "  model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "  optimizer = Adam(lr=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "tasks = [task for cluster in clusters for task in cluster]\n",
    "for task in tasks:\n",
    "    print('learning', task)\n",
    "    model = build_single_task_model(N=N, F=F, S=S)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    # es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)\n",
    "    model.fit([X_train, A_train, E_train],\n",
    "             y_train[[task]].values,\n",
    "             batch_size=batch_size,\n",
    "             validation_split=0.1,\n",
    "             epochs=epochs)\n",
    "    model.save_weights(generate_single_task_filename(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_compile_model(task):\n",
    "    model = build_single_task_model(N=N, F=F, S=S)\n",
    "    model.load_weights(generate_single_task_filename(task))\n",
    "    model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transfer_coefficient_from_file(task_learned, task_transferred, y_transferred_test):\n",
    "    model_learned = build_single_task_model(N=N, F=F, S=S)\n",
    "    model_transferred = build_single_task_model(N=N, F=F, S=S)\n",
    "    model_learned.load_weights(generate_single_task_filename(task_learned))\n",
    "    model_transferred.load_weights(generate_single_task_filename(task_transferred))\n",
    "    \n",
    "    layers_learned = model_learned.get_weights()\n",
    "    layers_transferred = model_transferred.get_weights()    \n",
    "    \n",
    "    # 10 is a hard-coded value dependent on the architecture\n",
    "    layers_transferred = layers_learned[:10] + layers_transferred[10:]\n",
    "    model_transferred.set_weights(layers_transferred)\n",
    "    model_transferred.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    eval_results = model_transferred.evaluate([X_test, A_test, E_test],\n",
    "                                              y_transferred_test,\n",
    "                                              batch_size=batch_size)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test_single_task_model(task_learned, y_test):\n",
    "    model = build_single_task_model(N=N, F=F, S=S)\n",
    "    model.load_weights(path.join('single_task_trained_models', task_learned + '.h5'))\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    eval_results = model.evaluate([X_test, A_test, E_test], y_test, batch_size=batch_size)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_and_test_single_task_model('A', y_test[['A']].values))\n",
    "print(calculate_transfer_coefficient_from_file('A', 'B', y_test[['B']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasks)\n",
    "transfer_coefficient_dict = dict()\n",
    "for task_learned, task_transferred in itertools.permutations(tasks, 2):\n",
    "    print(task_learned, task_transferred)\n",
    "    transfer_coefficient = calculate_transfer_coefficient_from_file(task_learned, task_transferred, y_test[[task_transferred]].values)\n",
    "    print(transfer_coefficient)\n",
    "    \n",
    "    if task_learned not in transfer_coefficient_dict.keys():\n",
    "        transfer_coefficient_dict[task_learned] = {task_transferred: transfer_coefficient}\n",
    "    else:\n",
    "        transfer_coefficient_dict[task_learned][task_transferred] = transfer_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('cross_task_transfer_coefficients.txt', 'w')\n",
    "for key1, value in transfer_coefficient_dict.items():\n",
    "    for key2, coef in value.items():\n",
    "        print(key1, key2, coef)\n",
    "        print(key1, key2, coef, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest of this file is comprised of mostly useless analysis code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transfer_coefficients():\n",
    "    with open('cross_task_transfer_coefficients.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        transfer_coefficient_dict = dict()\n",
    "        for line in lines:\n",
    "            task_learned, task_transferred, transfer_coefficient = line.strip().split()\n",
    "            if task_learned not in transfer_coefficient_dict.keys():\n",
    "                transfer_coefficient_dict[task_learned] = {task_transferred: float(transfer_coefficient)}\n",
    "            else:\n",
    "                transfer_coefficient_dict[task_learned][task_transferred] = float(transfer_coefficient)\n",
    "        return transfer_coefficient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_coefficient = analyze_transfer_coefficients()\n",
    "coef_list = list()\n",
    "# relevant_tasks = ['alpha', 'homo', 'lumo', 'gap']\n",
    "relevant_tasks = ['mu', 'homo']\n",
    "for task_set in itertools.combinations(relevant_tasks, 3):\n",
    "    coef_sum = 0\n",
    "    for i, j in itertools.combinations(task_set, 2):\n",
    "        coef_sum += transfer_coefficient[i][j]**2 + transfer_coefficient[j][i]**2\n",
    "    coef_list.append((coef_sum, task_set))\n",
    "# coef_list = np.asarray(coef_list)\n",
    "# coef_list = np.sort(coef_list)\n",
    "coef_list.sort()\n",
    "for entry in coef_list:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in itertools.combinations(transfer_coefficient.keys(), 2):\n",
    "    if transfer_coefficient[i][j] < 0.9 and transfer_coefficient[j][i] < 0.9:\n",
    "        print(i, \n",
    "              j, \n",
    "              round(transfer_coefficient[i][j], 3), \n",
    "              round(transfer_coefficient[j][i], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}