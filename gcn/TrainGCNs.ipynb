{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.backend import mean, square\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot\n",
    "\n",
    "from os import path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_complete, X_complete, E_complete, y_complete = qm9.load_data(return_type='numpy',\n",
    "                           nf_keys='atomic_num',\n",
    "                           ef_keys='type',\n",
    "                           self_loops=True,\n",
    "                           amount=None)  # Set to None to train on whole dataset\n",
    "# one-hot labeling of atoms\n",
    "uniq_X = np.unique(X_complete)\n",
    "X_complete = label_to_one_hot(X_complete, uniq_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, X, E = list(), list(), list()\n",
    "y = y_complete.sample(10000)\n",
    "for index, row in y.iterrows():\n",
    "    A.append(A_complete[index])\n",
    "    X.append(X_complete[index])\n",
    "    E.append(E_complete[index])\n",
    "A = np.stack(A, axis=0)\n",
    "X = np.stack(X, axis=0)\n",
    "E = np.stack(E, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = list(y.columns)[1:]\n",
    "y_list = []\n",
    "for task in tasks:\n",
    "    y_list.append(y[[task]].values)\n",
    "for i in range(len(y_list)):\n",
    "    y_list[i] = StandardScaler().fit_transform(y_list[i]).reshape(-1, y_list[0].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[-2]\n",
    "F = X.shape[-1] \n",
    "S = E.shape[-1]\n",
    "n_out = y_list[0].shape[-1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "es_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learning_rate)\n",
    "loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, \\\n",
    "X_train, X_test, \\\n",
    "E_train, E_test, \\\n",
    "*y_train_test_list = train_test_split(A, X, E, *y_list, test_size = 0.1)\n",
    "\n",
    "y_train_list = y_train_test_list[::2]\n",
    "y_test_list = y_train_test_list[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = Input(shape=(N, F))\n",
    "A_in = Input(shape=(N, N))\n",
    "E_in = Input(shape=(N, N, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_task_model(X_in, A_in, E_in):\n",
    "    gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "    gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "    pool = GlobalAttentionPool(256)(gc2)\n",
    "    dense1 = Dense(256, activation='relu')(pool)\n",
    "    output = Dense(n_out)(dense1)\n",
    "    return Model(inputs=[X_in, A_in, E_in], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(task):\n",
    "    return path.join('gcnmodels', task + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 15):\n",
    "    if i == 4:\n",
    "        continue\n",
    "    if i == 8:\n",
    "        continue\n",
    "    print('learning', tasks[i])\n",
    "    model = create_single_task_model(X_in, A_in, E_in)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)\n",
    "    model.fit([X_train, A_train, E_train],\n",
    "             y_train_list[i],\n",
    "             batch_size=batch_size,\n",
    "             validation_split=0.1,\n",
    "             epochs=epochs,\n",
    "             callbacks=[es_callback])\n",
    "    model.save_weights(generate_filename(tasks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
