{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.backend import mean, square\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalSumPool, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading QM9 dataset.\nReading SDF\n"
    }
   ],
   "source": [
    "A_all, X_all, E_all, y_all = qm9.load_data(return_type='numpy',\n",
    "                           nf_keys='atomic_num',\n",
    "                           ef_keys='type',\n",
    "                           self_loops=True,\n",
    "                           amount=None) # chnage this to None to load entire dataset\n",
    "# Preprocessing\n",
    "X_uniq = np.unique(X_all)\n",
    "X_uniq = X_uniq[X_uniq != 0]\n",
    "E_uniq = np.unique(E_all)\n",
    "E_uniq = E_uniq[E_uniq != 0]\n",
    "\n",
    "X_all = label_to_one_hot(X_all, X_uniq)\n",
    "E_all = label_to_one_hot(E_all, E_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = X_all.shape[-2]       # Number of nodes in the graphs\n",
    "F = X_all[0].shape[-1]    # Dimension of node features\n",
    "S = E_all[0].shape[-1]    # Dimension of edge features\n",
    "n_out = y_all.shape[-1]   # Dimension of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we don't want to train only on the lightest molecules\n",
    "# we randomly sample from the dataset\n",
    "indices = np.random.choice(X_all.shape[0], 10000, replace=False)\n",
    "X = X_all[indices, :, :]\n",
    "A = A_all[indices, :, :]\n",
    "E = E_all[indices, :, :, :]\n",
    "y = y_all.iloc[indices, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the means and stddevs here allows us \n",
    "# to normalize our data \n",
    "# TODO: shouldn't we store only the mean/stddev for the training data?\n",
    "task_to_scaler = dict()\n",
    "for task in list(y.columns)[1:]:\n",
    "    scaler = StandardScaler()\n",
    "    y.task = scaler.fit_transform(y[[task]])\n",
    "    task_to_scaler[task] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [['A', 'B', 'alpha'], \n",
    "            ['C', 'r2', 'u0'],\n",
    "            ['zpve', 'g298', 'cv'],\n",
    "            ['lumo', 'u298', 'h298'],\n",
    "            ['mu', 'homo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, \\\n",
    "    X_train, X_test, \\\n",
    "    E_train, E_test, \\\n",
    "    y_train, y_test = train_test_split(A, X, E, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_single_task_model(*, N, F, S):\n",
    "  X_in = Input(shape=(N, F))\n",
    "  A_in = Input(shape=(N, N))\n",
    "  E_in = Input(shape=(N, N, S))\n",
    "\n",
    "  gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "  gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "  pool = GlobalAttentionPool(256)(gc2)\n",
    "  dense = Dense(256, activation='relu')(pool)\n",
    "  output = Dense(1)(dense)\n",
    "\n",
    "  # Build model\n",
    "  model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "  optimizer = Adam(lr=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hard_sharing_model(*, N, F, S, num_tasks):\n",
    "  X_in = Input(shape=(N, F))\n",
    "  A_in = Input(shape=(N, N))\n",
    "  E_in = Input(shape=(N, N, S))\n",
    "\n",
    "  gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "  gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "  pool = GlobalAttentionPool(256)(gc2)\n",
    "  dense_list = [Dense(256, activation='relu')(pool) for i in range(num_tasks)]\n",
    "  output_list = [Dense(1)(dense_layer) for dense_layer in dense_list]\n",
    "\n",
    "  # Build model\n",
    "  model = Model(inputs=[X_in, A_in, E_in], outputs=output_list)\n",
    "  optimizer = Adam(lr=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_soft_sharing_model(*, N, F, S, num_tasks, share_param):\n",
    "  X_in = Input(shape=(N, F))\n",
    "  A_in = Input(shape=(N, N))\n",
    "  E_in = Input(shape=(N, N, S))\n",
    "\n",
    "  gc1_list = [EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in]) for i in range(num_tasks)]\n",
    "  gc2_list = [EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in]) for gc1 in gc1_list]\n",
    "  pool_list = [GlobalAttentionPool(256)(gc2) for gc2 in gc2_list]\n",
    "  dense_list = [Dense(256, activation='relu')(pool) for pool in pool_list]\n",
    "  output_list = [Dense(1)(dense) for dense in dense_list]\n",
    "\n",
    "  def loss(y_actual, y_pred):\n",
    "    avg_layer_diff = 0\n",
    "    for i in range(num_tasks):\n",
    "      for j in range(i):\n",
    "        for gc in [gc1_list, gc2_list]:\n",
    "          avg_layer_diff += mean(square(gc[i].trainable_weights - gc[j].trainable_weights))\n",
    "    avg_layer_diff /= (num_tasks)*(num_tasks-1)/2  \n",
    "    return mean(square(y_actual - y_pred)) + share_param*avg_layer_diff\n",
    "\n",
    "  # Build model\n",
    "  model = Model(inputs=[X_in, A_in, E_in], outputs=output_list)\n",
    "  optimizer = Adam(lr=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER_PATH = '/content/drive/My Drive/Colab Notebooks/demo_models'\n",
    "FOLDER_PATH = 'demo_models'\n",
    "\n",
    "def generate_model_filename(tasks):\n",
    "  filename = \"\".join(sorted(tasks))\n",
    "  return path.join(FOLDER_PATH, filename + '.h5')\n",
    "  # return filename + '.h5'\n",
    "\n",
    "def generate_task_scaler_filename(task):\n",
    "  return path.join(FOLDER_PATH, task + '.txt')\n",
    "  # return task + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tasks):\n",
    "  model.save_weights(generate_model_filename(tasks))\n",
    "  for task in tasks:\n",
    "    scaler_filename = generate_task_scaler_filename(task)\n",
    "    with open(scaler_filename, 'w') as f:\n",
    "      print(task_to_scaler[task].mean_[0], file=f)\n",
    "      print(task_to_scaler[task].scale_[0], file=f)\n",
    "\n",
    "def load_hard_sharing_model(*, N, F, S, tasks):\n",
    "  model = build_hard_sharing_model(N=N, F=F, S=S, num_tasks=len(tasks))\n",
    "  model.load_weights(generate_model_filename(tasks))\n",
    "  task_to_scaler = dict()\n",
    "  for task in tasks:\n",
    "    with open(generate_task_scaler_filename(task), 'r') as f:\n",
    "      lines = f.readlines()\n",
    "      scaler = StandardScaler()\n",
    "      scaler.mean_ = float(lines[0].strip())\n",
    "      scaler.scale_ = float(lines[1].strip())\n",
    "      task_to_scaler[task] = scaler\n",
    "  return model, task_to_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_property(prop, mol_id, clusters, N=N, F=F, S=S):\n",
    "  for cluster in clusters:\n",
    "    if prop in cluster:\n",
    "      model, task_to_scaler = load_hard_sharing_model(N=N, F=F, S=S, tasks=cluster)\n",
    "      i = mol_id - 1\n",
    "\n",
    "      # convert shape for batch mode\n",
    "      def wrap(a):\n",
    "        return a.reshape([1] + list(a.shape))\n",
    "      x = list(map(wrap, [X_all[i], A_all[i], E_all[i]]))\n",
    "\n",
    "      cluster_prediction = model.predict(x)\n",
    "      prediction = cluster_prediction[cluster.index(prop)]\n",
    "      prediction = task_to_scaler[prop].inverse_transform(prediction)\n",
    "      # print(prediction)\n",
    "      return prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "675.4141 - val_dense_39_loss: 41890.8008 - val_dense_40_loss: 41890.8867 - val_dense_41_loss: 41893.7344\nEpoch 5/25\n26/26 [==============================] - 14s 524ms/step - loss: 122282.9297 - dense_39_loss: 40760.8750 - dense_40_loss: 40760.8711 - dense_41_loss: 40761.1680 - val_loss: 125637.3672 - val_dense_39_loss: 41878.9727 - val_dense_40_loss: 41879.1328 - val_dense_41_loss: 41879.2617\nEpoch 6/25\n26/26 [==============================] - 14s 528ms/step - loss: 122237.3750 - dense_39_loss: 40745.7812 - dense_40_loss: 40745.7773 - dense_41_loss: 40745.8008 - val_loss: 125606.2656 - val_dense_39_loss: 41868.7930 - val_dense_40_loss: 41868.7852 - val_dense_41_loss: 41868.6953\nEpoch 7/25\n26/26 [==============================] - 14s 523ms/step - loss: 122217.4609 - dense_39_loss: 40739.1445 - dense_40_loss: 40739.1484 - dense_41_loss: 40739.1719 - val_loss: 125592.3750 - val_dense_39_loss: 41864.1289 - val_dense_40_loss: 41864.1211 - val_dense_41_loss: 41864.1289\nEpoch 8/25\n26/26 [==============================] - 14s 527ms/step - loss: 122205.3906 - dense_39_loss: 40735.1406 - dense_40_loss: 40735.1367 - dense_41_loss: 40735.1211 - val_loss: 125586.5859 - val_dense_39_loss: 41862.1758 - val_dense_40_loss: 41862.1797 - val_dense_41_loss: 41862.2344\nEpoch 9/25\n26/26 [==============================] - 14s 524ms/step - loss: 122199.9922 - dense_39_loss: 40733.3242 - dense_40_loss: 40733.3242 - dense_41_loss: 40733.3398 - val_loss: 125580.7969 - val_dense_39_loss: 41860.2578 - val_dense_40_loss: 41860.2539 - val_dense_41_loss: 41860.2852\nEpoch 10/25\n26/26 [==============================] - 14s 525ms/step - loss: 122196.1094 - dense_39_loss: 40732.0391 - dense_40_loss: 40732.0352 - dense_41_loss: 40732.0391 - val_loss: 125579.7578 - val_dense_39_loss: 41859.8906 - val_dense_40_loss: 41859.8945 - val_dense_41_loss: 41859.9727\nEpoch 11/25\n26/26 [==============================] - 14s 529ms/step - loss: 122194.3516 - dense_39_loss: 40731.4414 - dense_40_loss: 40731.4453 - dense_41_loss: 40731.4648 - val_loss: 125576.4766 - val_dense_39_loss: 41858.8281 - val_dense_40_loss: 41858.8203 - val_dense_41_loss: 41858.8359\nEpoch 12/25\n26/26 [==============================] - 14s 521ms/step - loss: 122193.6719 - dense_39_loss: 40731.2188 - dense_40_loss: 40731.2188 - dense_41_loss: 40731.2383 - val_loss: 125573.8906 - val_dense_39_loss: 41857.9570 - val_dense_40_loss: 41857.9531 - val_dense_41_loss: 41857.9844\nEpoch 13/25\n26/26 [==============================] - 14s 524ms/step - loss: 122191.3984 - dense_39_loss: 40730.4688 - dense_40_loss: 40730.4648 - dense_41_loss: 40730.4688 - val_loss: 125572.7031 - val_dense_39_loss: 41857.5547 - val_dense_40_loss: 41857.5547 - val_dense_41_loss: 41857.5898\nEpoch 14/25\n26/26 [==============================] - 14s 525ms/step - loss: 122190.6953 - dense_39_loss: 40730.2305 - dense_40_loss: 40730.2305 - dense_41_loss: 40730.2344 - val_loss: 125571.6875 - val_dense_39_loss: 41857.2266 - val_dense_40_loss: 41857.2227 - val_dense_41_loss: 41857.2461\nEpoch 15/25\n26/26 [==============================] - 14s 521ms/step - loss: 122190.0938 - dense_39_loss: 40730.0273 - dense_40_loss: 40730.0234 - dense_41_loss: 40730.0312 - val_loss: 125572.4453 - val_dense_39_loss: 41857.4766 - val_dense_40_loss: 41857.4766 - val_dense_41_loss: 41857.4961\nEpoch 16/25\n26/26 [==============================] - 15s 574ms/step - loss: 122189.3828 - dense_39_loss: 40729.7930 - dense_40_loss: 40729.7891 - dense_41_loss: 40729.7930 - val_loss: 125571.0234 - val_dense_39_loss: 41857.0039 - val_dense_40_loss: 41857.0000 - val_dense_41_loss: 41857.0234\nEpoch 17/25\n26/26 [==============================] - 18s 688ms/step - loss: 122189.2734 - dense_39_loss: 40729.7617 - dense_40_loss: 40729.7500 - dense_41_loss: 40729.7578 - val_loss: 125574.2344 - val_dense_39_loss: 41858.0508 - val_dense_40_loss: 41858.0625 - val_dense_41_loss: 41858.1289\nEpoch 18/25\n26/26 [==============================] - 18s 693ms/step - loss: 122189.1562 - dense_39_loss: 40729.7188 - dense_40_loss: 40729.7148 - dense_41_loss: 40729.7227 - val_loss: 125569.6641 - val_dense_39_loss: 41856.5547 - val_dense_40_loss: 41856.5508 - val_dense_41_loss: 41856.5586\nEpoch 19/25\n26/26 [==============================] - 17s 666ms/step - loss: 122188.4844 - dense_39_loss: 40729.4922 - dense_40_loss: 40729.4883 - dense_41_loss: 40729.4961 - val_loss: 125570.9297 - val_dense_39_loss: 41856.9766 - val_dense_40_loss: 41856.9727 - val_dense_41_loss: 41856.9961\nEpoch 20/25\n26/26 [==============================] - 18s 678ms/step - loss: 122188.4062 - dense_39_loss: 40729.4648 - dense_40_loss: 40729.4648 - dense_41_loss: 40729.4766 - val_loss: 125570.4453 - val_dense_39_loss: 41856.8125 - val_dense_40_loss: 41856.8125 - val_dense_41_loss: 41856.8242\nEpoch 21/25\n26/26 [==============================] - 17s 654ms/step - loss: 122188.0781 - dense_39_loss: 40729.3594 - dense_40_loss: 40729.3516 - dense_41_loss: 40729.3711 - val_loss: 125568.8203 - val_dense_39_loss: 41856.2734 - val_dense_40_loss: 41856.2695 - val_dense_41_loss: 41856.2734\nEpoch 22/25\n26/26 [==============================] - 18s 684ms/step - loss: 122188.1406 - dense_39_loss: 40729.3672 - dense_40_loss: 40729.3672 - dense_41_loss: 40729.3984 - val_loss: 125570.1797 - val_dense_39_loss: 41856.6914 - val_dense_40_loss: 41856.7031 - val_dense_41_loss: 41856.7852\nEpoch 23/25\n26/26 [==============================] - 18s 674ms/step - loss: 122187.7266 - dense_39_loss: 40729.2305 - dense_40_loss: 40729.2305 - dense_41_loss: 40729.2578 - val_loss: 125569.9766 - val_dense_39_loss: 41856.6445 - val_dense_40_loss: 41856.6484 - val_dense_41_loss: 41856.6875\nEpoch 24/25\n26/26 [==============================] - 17s 657ms/step - loss: 122187.6406 - dense_39_loss: 40729.1992 - dense_40_loss: 40729.2031 - dense_41_loss: 40729.2344 - val_loss: 125567.4688 - val_dense_39_loss: 41855.8164 - val_dense_40_loss: 41855.8164 - val_dense_41_loss: 41855.8281\nEpoch 25/25\n26/26 [==============================] - 17s 652ms/step - loss: 122186.9453 - dense_39_loss: 40728.9727 - dense_40_loss: 40728.9727 - dense_41_loss: 40728.9844 - val_loss: 125572.3750 - val_dense_39_loss: 41857.4297 - val_dense_40_loss: 41857.4414 - val_dense_41_loss: 41857.5039\nEpoch 1/25\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_14/root_kernel:0', 'edge_conditioned_conv_15/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_14/root_kernel:0', 'edge_conditioned_conv_15/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_14/root_kernel:0', 'edge_conditioned_conv_15/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_14/root_kernel:0', 'edge_conditioned_conv_15/root_kernel:0'] when minimizing the loss.\n26/26 [==============================] - 18s 677ms/step - loss: 298587.3125 - dense_45_loss: 99512.7578 - dense_46_loss: 99718.3203 - dense_47_loss: 99356.2500 - val_loss: 136568.2656 - val_dense_45_loss: 45532.4766 - val_dense_46_loss: 46157.2461 - val_dense_47_loss: 44878.5469\nEpoch 2/25\n26/26 [==============================] - 17s 663ms/step - loss: 125696.0781 - dense_45_loss: 41877.4219 - dense_46_loss: 41638.1172 - dense_47_loss: 42180.5391 - val_loss: 118727.8672 - val_dense_45_loss: 39571.9141 - val_dense_46_loss: 39690.9688 - val_dense_47_loss: 39464.9883\nEpoch 3/25\n26/26 [==============================] - 18s 700ms/step - loss: 115818.2031 - dense_45_loss: 38605.6602 - dense_46_loss: 38661.5703 - dense_47_loss: 38550.9883 - val_loss: 117658.3984 - val_dense_45_loss: 39218.3594 - val_dense_46_loss: 39199.4102 - val_dense_47_loss: 39240.6328\nEpoch 4/25\n26/26 [==============================] - 17s 655ms/step - loss: 113800.1250 - dense_45_loss: 37933.1523 - dense_46_loss: 37930.7891 - dense_47_loss: 37936.2031 - val_loss: 116482.6250 - val_dense_45_loss: 38827.4766 - val_dense_46_loss: 38827.5312 - val_dense_47_loss: 38827.6094\nEpoch 5/25\n26/26 [==============================] - 17s 671ms/step - loss: 113314.8281 - dense_45_loss: 37771.4805 - dense_46_loss: 37771.6562 - dense_47_loss: 37771.6914 - val_loss: 116301.9297 - val_dense_45_loss: 38767.2461 - val_dense_46_loss: 38767.6484 - val_dense_47_loss: 38767.0273\nEpoch 6/25\n26/26 [==============================] - 18s 683ms/step - loss: 113120.7031 - dense_45_loss: 37706.7891 - dense_46_loss: 37707.0312 - dense_47_loss: 37706.8555 - val_loss: 116204.7969 - val_dense_45_loss: 38734.8945 - val_dense_46_loss: 38734.9766 - val_dense_47_loss: 38734.9297\nEpoch 7/25\n26/26 [==============================] - 18s 678ms/step - loss: 113030.4766 - dense_45_loss: 37676.7500 - dense_46_loss: 37676.9141 - dense_47_loss: 37676.8164 - val_loss: 116166.9141 - val_dense_45_loss: 38722.2930 - val_dense_46_loss: 38722.3281 - val_dense_47_loss: 38722.2852\nEpoch 8/25\n26/26 [==============================] - 18s 699ms/step - loss: 112978.5781 - dense_45_loss: 37659.4844 - dense_46_loss: 37659.5664 - dense_47_loss: 37659.5156 - val_loss: 116129.8594 - val_dense_45_loss: 38709.9570 - val_dense_46_loss: 38709.9570 - val_dense_47_loss: 38709.9453\nEpoch 9/25\n26/26 [==============================] - 17s 663ms/step - loss: 112953.2969 - dense_45_loss: 37651.0781 - dense_46_loss: 37651.1250 - dense_47_loss: 37651.0898 - val_loss: 116127.6406 - val_dense_45_loss: 38709.2227 - val_dense_46_loss: 38709.2227 - val_dense_47_loss: 38709.1953\nEpoch 10/25\n26/26 [==============================] - 17s 669ms/step - loss: 112939.0000 - dense_45_loss: 37646.3242 - dense_46_loss: 37646.3438 - dense_47_loss: 37646.3320 - val_loss: 116097.8438 - val_dense_45_loss: 38699.2969 - val_dense_46_loss: 38699.2734 - val_dense_47_loss: 38699.2812\nEpoch 11/25\n26/26 [==============================] - 17s 663ms/step - loss: 112928.7422 - dense_45_loss: 37642.9180 - dense_46_loss: 37642.9180 - dense_47_loss: 37642.9141 - val_loss: 116091.2891 - val_dense_45_loss: 38697.1094 - val_dense_46_loss: 38697.0898 - val_dense_47_loss: 38697.0898\nEpoch 12/25\n26/26 [==============================] - 15s 592ms/step - loss: 112921.5625 - dense_45_loss: 37640.5273 - dense_46_loss: 37640.5156 - dense_47_loss: 37640.5156 - val_loss: 116093.6797 - val_dense_45_loss: 38697.9102 - val_dense_46_loss: 38697.8906 - val_dense_47_loss: 38697.8711\nEpoch 13/25\n26/26 [==============================] - 14s 523ms/step - loss: 112915.4531 - dense_45_loss: 37638.4922 - dense_46_loss: 37638.4766 - dense_47_loss: 37638.4883 - val_loss: 116098.6875 - val_dense_45_loss: 38699.5781 - val_dense_46_loss: 38699.5703 - val_dense_47_loss: 38699.5430\nEpoch 14/25\n26/26 [==============================] - 14s 549ms/step - loss: 112911.6641 - dense_45_loss: 37637.2305 - dense_46_loss: 37637.2031 - dense_47_loss: 37637.2188 - val_loss: 116086.3359 - val_dense_45_loss: 38695.4766 - val_dense_46_loss: 38695.4375 - val_dense_47_loss: 38695.4180\nEpoch 15/25\n26/26 [==============================] - 14s 520ms/step - loss: 112906.6797 - dense_45_loss: 37635.5664 - dense_46_loss: 37635.5547 - dense_47_loss: 37635.5625 - val_loss: 116067.5000 - val_dense_45_loss: 38689.1836 - val_dense_46_loss: 38689.1562 - val_dense_47_loss: 38689.1602\nEpoch 16/25\n26/26 [==============================] - 14s 556ms/step - loss: 112907.4688 - dense_45_loss: 37635.8320 - dense_46_loss: 37635.8125 - dense_47_loss: 37635.8281 - val_loss: 116080.3984 - val_dense_45_loss: 38693.5000 - val_dense_46_loss: 38693.4531 - val_dense_47_loss: 38693.4492\nEpoch 17/25\n26/26 [==============================] - 14s 523ms/step - loss: 112904.7109 - dense_45_loss: 37634.9141 - dense_46_loss: 37634.8828 - dense_47_loss: 37634.9023 - val_loss: 116082.9766 - val_dense_45_loss: 38694.3516 - val_dense_46_loss: 38694.3203 - val_dense_47_loss: 38694.3047\nEpoch 18/25\n26/26 [==============================] - 14s 520ms/step - loss: 112901.0859 - dense_45_loss: 37633.7109 - dense_46_loss: 37633.6875 - dense_47_loss: 37633.7031 - val_loss: 116068.7969 - val_dense_45_loss: 38689.6133 - val_dense_46_loss: 38689.5938 - val_dense_47_loss: 38689.5898\nEpoch 19/25\n26/26 [==============================] - 14s 526ms/step - loss: 112900.8672 - dense_45_loss: 37633.6289 - dense_46_loss: 37633.6172 - dense_47_loss: 37633.6211 - val_loss: 116063.1641 - val_dense_45_loss: 38687.7344 - val_dense_46_loss: 38687.7109 - val_dense_47_loss: 38687.7148\nEpoch 20/25\n26/26 [==============================] - 14s 526ms/step - loss: 112894.1406 - dense_45_loss: 37631.3906 - dense_46_loss: 37631.3672 - dense_47_loss: 37631.3789 - val_loss: 116056.7031 - val_dense_45_loss: 38685.5820 - val_dense_46_loss: 38685.5547 - val_dense_47_loss: 38685.5547\nEpoch 21/25\n26/26 [==============================] - 14s 524ms/step - loss: 112891.7266 - dense_45_loss: 37630.5938 - dense_46_loss: 37630.5625 - dense_47_loss: 37630.5859 - val_loss: 116078.2656 - val_dense_45_loss: 38692.7734 - val_dense_46_loss: 38692.7773 - val_dense_47_loss: 38692.7109\nEpoch 22/25\n26/26 [==============================] - 14s 522ms/step - loss: 112901.3438 - dense_45_loss: 37633.7930 - dense_46_loss: 37633.7891 - dense_47_loss: 37633.7695 - val_loss: 116060.2891 - val_dense_45_loss: 38686.7852 - val_dense_46_loss: 38686.7539 - val_dense_47_loss: 38686.7578\nEpoch 23/25\n26/26 [==============================] - 14s 522ms/step - loss: 112901.5938 - dense_45_loss: 37633.8828 - dense_46_loss: 37633.8672 - dense_47_loss: 37633.8438 - val_loss: 116055.5078 - val_dense_45_loss: 38685.1836 - val_dense_46_loss: 38685.1836 - val_dense_47_loss: 38685.1445\nEpoch 24/25\n26/26 [==============================] - 14s 523ms/step - loss: 112889.4688 - dense_45_loss: 37629.8242 - dense_46_loss: 37629.8047 - dense_47_loss: 37629.8164 - val_loss: 116047.0781 - val_dense_45_loss: 38682.3789 - val_dense_46_loss: 38682.3477 - val_dense_47_loss: 38682.3594\nEpoch 25/25\n26/26 [==============================] - 14s 522ms/step - loss: 112884.8906 - dense_45_loss: 37628.3125 - dense_46_loss: 37628.2891 - dense_47_loss: 37628.3008 - val_loss: 116052.3359 - val_dense_45_loss: 38684.1289 - val_dense_46_loss: 38684.1133 - val_dense_47_loss: 38684.1016\nEpoch 1/25\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_16/root_kernel:0', 'edge_conditioned_conv_17/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_16/root_kernel:0', 'edge_conditioned_conv_17/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_16/root_kernel:0', 'edge_conditioned_conv_17/root_kernel:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['edge_conditioned_conv_16/root_kernel:0', 'edge_conditioned_conv_17/root_kernel:0'] when minimizing the loss.\n26/26 [==============================] - 14s 532ms/step - loss: 7.1612 - dense_50_loss: 3.5836 - dense_51_loss: 3.5776 - val_loss: 6.0334 - val_dense_50_loss: 3.0161 - val_dense_51_loss: 3.0173\nEpoch 2/25\n26/26 [==============================] - 13s 519ms/step - loss: 6.5114 - dense_50_loss: 3.2552 - dense_51_loss: 3.2562 - val_loss: 5.9305 - val_dense_50_loss: 2.9644 - val_dense_51_loss: 2.9661\nEpoch 3/25\n26/26 [==============================] - 14s 524ms/step - loss: 6.4157 - dense_50_loss: 3.2079 - dense_51_loss: 3.2078 - val_loss: 5.8686 - val_dense_50_loss: 2.9346 - val_dense_51_loss: 2.9340\nEpoch 4/25\n26/26 [==============================] - 13s 507ms/step - loss: 6.4356 - dense_50_loss: 3.2182 - dense_51_loss: 3.2174 - val_loss: 5.7870 - val_dense_50_loss: 2.8934 - val_dense_51_loss: 2.8936\nEpoch 5/25\n26/26 [==============================] - 14s 522ms/step - loss: 6.3437 - dense_50_loss: 3.1722 - dense_51_loss: 3.1715 - val_loss: 5.7791 - val_dense_50_loss: 2.8906 - val_dense_51_loss: 2.8885\nEpoch 6/25\n26/26 [==============================] - 14s 532ms/step - loss: 6.3466 - dense_50_loss: 3.1750 - dense_51_loss: 3.1717 - val_loss: 5.7798 - val_dense_50_loss: 2.8896 - val_dense_51_loss: 2.8902\nEpoch 7/25\n26/26 [==============================] - 15s 566ms/step - loss: 6.3247 - dense_50_loss: 3.1629 - dense_51_loss: 3.1617 - val_loss: 5.7652 - val_dense_50_loss: 2.8825 - val_dense_51_loss: 2.8828\nEpoch 8/25\n26/26 [==============================] - 20s 753ms/step - loss: 6.3155 - dense_50_loss: 3.1579 - dense_51_loss: 3.1577 - val_loss: 5.7655 - val_dense_50_loss: 2.8846 - val_dense_51_loss: 2.8808\nEpoch 9/25\n26/26 [==============================] - 20s 778ms/step - loss: 6.2962 - dense_50_loss: 3.1489 - dense_51_loss: 3.1473 - val_loss: 5.7439 - val_dense_50_loss: 2.8728 - val_dense_51_loss: 2.8711\nEpoch 10/25\n26/26 [==============================] - 19s 713ms/step - loss: 6.2828 - dense_50_loss: 3.1426 - dense_51_loss: 3.1403 - val_loss: 5.8253 - val_dense_50_loss: 2.9134 - val_dense_51_loss: 2.9119\nEpoch 11/25\n26/26 [==============================] - 18s 708ms/step - loss: 6.2758 - dense_50_loss: 3.1387 - dense_51_loss: 3.1370 - val_loss: 5.7196 - val_dense_50_loss: 2.8601 - val_dense_51_loss: 2.8595\nEpoch 12/25\n26/26 [==============================] - 18s 711ms/step - loss: 6.2861 - dense_50_loss: 3.1428 - dense_51_loss: 3.1433 - val_loss: 5.7696 - val_dense_50_loss: 2.8869 - val_dense_51_loss: 2.8826\nEpoch 13/25\n26/26 [==============================] - 19s 739ms/step - loss: 6.2715 - dense_50_loss: 3.1369 - dense_51_loss: 3.1347 - val_loss: 5.7289 - val_dense_50_loss: 2.8644 - val_dense_51_loss: 2.8645\nEpoch 14/25\n26/26 [==============================] - 19s 716ms/step - loss: 6.2406 - dense_50_loss: 3.1204 - dense_51_loss: 3.1201 - val_loss: 5.7952 - val_dense_50_loss: 2.8989 - val_dense_51_loss: 2.8962\nEpoch 15/25\n26/26 [==============================] - 19s 728ms/step - loss: 6.2500 - dense_50_loss: 3.1259 - dense_51_loss: 3.1241 - val_loss: 5.7753 - val_dense_50_loss: 2.8855 - val_dense_51_loss: 2.8898\nEpoch 16/25\n26/26 [==============================] - 15s 567ms/step - loss: 6.1949 - dense_50_loss: 3.0984 - dense_51_loss: 3.0965 - val_loss: 5.7127 - val_dense_50_loss: 2.8559 - val_dense_51_loss: 2.8569\nEpoch 17/25\n26/26 [==============================] - 17s 664ms/step - loss: 6.2095 - dense_50_loss: 3.1044 - dense_51_loss: 3.1051 - val_loss: 5.7190 - val_dense_50_loss: 2.8594 - val_dense_51_loss: 2.8596\nEpoch 18/25\n26/26 [==============================] - 18s 707ms/step - loss: 6.1758 - dense_50_loss: 3.0882 - dense_51_loss: 3.0877 - val_loss: 5.7172 - val_dense_50_loss: 2.8585 - val_dense_51_loss: 2.8587\nEpoch 19/25\n26/26 [==============================] - 18s 708ms/step - loss: 6.1599 - dense_50_loss: 3.0809 - dense_51_loss: 3.0790 - val_loss: 5.7216 - val_dense_50_loss: 2.8614 - val_dense_51_loss: 2.8602\nEpoch 20/25\n26/26 [==============================] - 19s 722ms/step - loss: 6.1589 - dense_50_loss: 3.0795 - dense_51_loss: 3.0793 - val_loss: 5.7989 - val_dense_50_loss: 2.8986 - val_dense_51_loss: 2.9002\nEpoch 21/25\n26/26 [==============================] - 18s 696ms/step - loss: 6.1689 - dense_50_loss: 3.0852 - dense_51_loss: 3.0836 - val_loss: 5.7589 - val_dense_50_loss: 2.8801 - val_dense_51_loss: 2.8788\nEpoch 22/25\n26/26 [==============================] - 18s 703ms/step - loss: 6.1431 - dense_50_loss: 3.0719 - dense_51_loss: 3.0713 - val_loss: 5.7373 - val_dense_50_loss: 2.8692 - val_dense_51_loss: 2.8680\nEpoch 23/25\n26/26 [==============================] - 17s 652ms/step - loss: 6.1838 - dense_50_loss: 3.0926 - dense_51_loss: 3.0912 - val_loss: 5.8230 - val_dense_50_loss: 2.9139 - val_dense_51_loss: 2.9091\nEpoch 24/25\n26/26 [==============================] - 15s 584ms/step - loss: 6.1970 - dense_50_loss: 3.0984 - dense_51_loss: 3.0986 - val_loss: 5.7416 - val_dense_50_loss: 2.8704 - val_dense_51_loss: 2.8713\nEpoch 25/25\n26/26 [==============================] - 19s 723ms/step - loss: 6.1545 - dense_50_loss: 3.0774 - dense_51_loss: 3.0771 - val_loss: 5.7796 - val_dense_50_loss: 2.8910 - val_dense_51_loss: 2.8887\n"
    }
   ],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "  for cluster in clusters:\n",
    "    model = build_hard_sharing_model(N=N, F=F, S=S, num_tasks=len(cluster))\n",
    "    model.fit(x=[X_train, A_train, E_train], \n",
    "              y=y_train[cluster].values,\n",
    "              batch_size=batch_size,\n",
    "              validation_split=0.1,\n",
    "              epochs=25)\n",
    "    save_model(model, cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4/4 [==============================] - 1s 149ms/step - loss: 3665.6887 - dense_55_loss: 1221.8907 - dense_56_loss: 1221.8964 - dense_57_loss: 1221.9017\nTest loss: [3665.688720703125, 1221.8907470703125, 1221.8963623046875, 1221.9017333984375]\n4/4 [==============================] - 1s 157ms/step - loss: 1594318.2500 - dense_61_loss: 531437.8125 - dense_62_loss: 531440.0625 - dense_63_loss: 531440.2500\nTest loss: [1594318.25, 531437.8125, 531440.0625, 531440.25]\n4/4 [==============================] - 1s 154ms/step - loss: 187469.5156 - dense_67_loss: 62490.6836 - dense_68_loss: 62489.3086 - dense_69_loss: 62489.5312\nTest loss: [187469.515625, 62490.68359375, 62489.30859375, 62489.53125]\n4/4 [==============================] - 1s 151ms/step - loss: 374097.8125 - dense_73_loss: 124700.9219 - dense_74_loss: 124698.2188 - dense_75_loss: 124698.6484\nTest loss: [374097.8125, 124700.921875, 124698.21875, 124698.6484375]\n4/4 [==============================] - 1s 152ms/step - loss: 1952.1123 - dense_79_loss: 650.8391 - dense_80_loss: 650.6215 - dense_81_loss: 650.6517\nTest loss: [1952.1123046875, 650.8390502929688, 650.6215209960938, 650.6517333984375]\n"
    }
   ],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "    for cluster in clusters:\n",
    "      model, _ = load_hard_sharing_model(N=N, F=F, S=S, tasks=clusters[0])\n",
    "      model_loss = model.evaluate(x=[X_test, A_test, E_test],\n",
    "                                    y=y_test[cluster].values)\n",
    "      print(f\"Test loss: {model_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[19.47965]]\n19.47965\n"
    }
   ],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "    print(predict_property('A', 1, clusters, N=N, F=F, S=S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
