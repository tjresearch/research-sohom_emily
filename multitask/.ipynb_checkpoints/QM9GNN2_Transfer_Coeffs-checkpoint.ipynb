{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.backend import mean, square\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 4343.30it/s]\n"
     ]
    }
   ],
   "source": [
    "A, X, E, y = qm9.load_data(return_type='numpy',\n",
    "                          nf_keys='atomic_num',\n",
    "                          ef_keys='type',\n",
    "                          self_loops=True,\n",
    "                          amount=4000)\n",
    "uniq_X = np.unique(X)\n",
    "X = label_to_one_hot(X, uniq_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0_atom</th>\n",
       "      <th>u298_atom</th>\n",
       "      <th>h298_atom</th>\n",
       "      <th>g298_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gdb_1</td>\n",
       "      <td>157.71180</td>\n",
       "      <td>157.709970</td>\n",
       "      <td>157.706990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478930</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-395.999595</td>\n",
       "      <td>-398.643290</td>\n",
       "      <td>-401.014647</td>\n",
       "      <td>-372.471772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>gdb_2</td>\n",
       "      <td>293.60975</td>\n",
       "      <td>293.541110</td>\n",
       "      <td>191.393970</td>\n",
       "      <td>1.6256</td>\n",
       "      <td>9.46</td>\n",
       "      <td>-0.2570</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>26.1563</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>-56.525887</td>\n",
       "      <td>-56.523026</td>\n",
       "      <td>-56.522082</td>\n",
       "      <td>-56.544961</td>\n",
       "      <td>6.316</td>\n",
       "      <td>-276.861363</td>\n",
       "      <td>-278.620271</td>\n",
       "      <td>-280.399259</td>\n",
       "      <td>-259.338802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gdb_3</td>\n",
       "      <td>799.58812</td>\n",
       "      <td>437.903860</td>\n",
       "      <td>282.945450</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-0.2928</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>19.0002</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>-76.404702</td>\n",
       "      <td>-76.401867</td>\n",
       "      <td>-76.400922</td>\n",
       "      <td>-76.422349</td>\n",
       "      <td>6.002</td>\n",
       "      <td>-213.087624</td>\n",
       "      <td>-213.974294</td>\n",
       "      <td>-215.159658</td>\n",
       "      <td>-201.407171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gdb_4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.28</td>\n",
       "      <td>-0.2845</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>59.5248</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>-77.308427</td>\n",
       "      <td>-77.305527</td>\n",
       "      <td>-77.304583</td>\n",
       "      <td>-77.327429</td>\n",
       "      <td>8.574</td>\n",
       "      <td>-385.501997</td>\n",
       "      <td>-387.237686</td>\n",
       "      <td>-389.016047</td>\n",
       "      <td>-365.800724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gdb_5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.593883</td>\n",
       "      <td>44.593883</td>\n",
       "      <td>2.8937</td>\n",
       "      <td>12.99</td>\n",
       "      <td>-0.3604</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>48.7476</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>-93.411888</td>\n",
       "      <td>-93.409370</td>\n",
       "      <td>-93.408425</td>\n",
       "      <td>-93.431246</td>\n",
       "      <td>6.278</td>\n",
       "      <td>-301.820534</td>\n",
       "      <td>-302.906752</td>\n",
       "      <td>-304.091489</td>\n",
       "      <td>-288.720028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3995</td>\n",
       "      <td>gdb_3996</td>\n",
       "      <td>3.33117</td>\n",
       "      <td>1.516440</td>\n",
       "      <td>1.358690</td>\n",
       "      <td>1.0785</td>\n",
       "      <td>68.31</td>\n",
       "      <td>-0.2459</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.2469</td>\n",
       "      <td>986.2809</td>\n",
       "      <td>0.139181</td>\n",
       "      <td>-400.944193</td>\n",
       "      <td>-400.935445</td>\n",
       "      <td>-400.934501</td>\n",
       "      <td>-400.977158</td>\n",
       "      <td>31.893</td>\n",
       "      <td>-1565.545221</td>\n",
       "      <td>-1575.164307</td>\n",
       "      <td>-1584.647850</td>\n",
       "      <td>-1452.224626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>gdb_3997</td>\n",
       "      <td>3.21675</td>\n",
       "      <td>1.545420</td>\n",
       "      <td>1.343710</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>68.25</td>\n",
       "      <td>-0.2486</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>983.7517</td>\n",
       "      <td>0.139515</td>\n",
       "      <td>-400.947904</td>\n",
       "      <td>-400.939105</td>\n",
       "      <td>-400.938161</td>\n",
       "      <td>-400.981336</td>\n",
       "      <td>32.281</td>\n",
       "      <td>-1567.873907</td>\n",
       "      <td>-1577.460990</td>\n",
       "      <td>-1586.944533</td>\n",
       "      <td>-1454.846359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3997</td>\n",
       "      <td>gdb_3998</td>\n",
       "      <td>3.70487</td>\n",
       "      <td>1.351230</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>70.97</td>\n",
       "      <td>-0.2459</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>1091.3741</td>\n",
       "      <td>0.091451</td>\n",
       "      <td>-361.346440</td>\n",
       "      <td>-361.337818</td>\n",
       "      <td>-361.336874</td>\n",
       "      <td>-361.379798</td>\n",
       "      <td>30.819</td>\n",
       "      <td>-1327.810927</td>\n",
       "      <td>-1333.955495</td>\n",
       "      <td>-1341.067054</td>\n",
       "      <td>-1241.734889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>gdb_3999</td>\n",
       "      <td>3.70937</td>\n",
       "      <td>1.364910</td>\n",
       "      <td>1.003890</td>\n",
       "      <td>4.0964</td>\n",
       "      <td>65.92</td>\n",
       "      <td>-0.2614</td>\n",
       "      <td>-0.0540</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>1060.7387</td>\n",
       "      <td>0.081305</td>\n",
       "      <td>-377.453740</td>\n",
       "      <td>-377.445525</td>\n",
       "      <td>-377.444580</td>\n",
       "      <td>-377.486899</td>\n",
       "      <td>28.613</td>\n",
       "      <td>-1246.538471</td>\n",
       "      <td>-1252.049255</td>\n",
       "      <td>-1258.567191</td>\n",
       "      <td>-1166.714934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>gdb_4000</td>\n",
       "      <td>3.32752</td>\n",
       "      <td>1.320310</td>\n",
       "      <td>1.010600</td>\n",
       "      <td>2.3826</td>\n",
       "      <td>66.14</td>\n",
       "      <td>-0.2489</td>\n",
       "      <td>-0.0553</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>1090.1851</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>-398.527244</td>\n",
       "      <td>-398.518642</td>\n",
       "      <td>-398.517698</td>\n",
       "      <td>-398.561461</td>\n",
       "      <td>29.522</td>\n",
       "      <td>-1304.591211</td>\n",
       "      <td>-1310.747702</td>\n",
       "      <td>-1317.859261</td>\n",
       "      <td>-1218.798181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mol_id          A           B           C      mu  alpha    homo  \\\n",
       "0        gdb_1  157.71180  157.709970  157.706990  0.0000  13.21 -0.3877   \n",
       "1        gdb_2  293.60975  293.541110  191.393970  1.6256   9.46 -0.2570   \n",
       "2        gdb_3  799.58812  437.903860  282.945450  1.8511   6.31 -0.2928   \n",
       "3        gdb_4    0.00000   35.610036   35.610036  0.0000  16.28 -0.2845   \n",
       "4        gdb_5    0.00000   44.593883   44.593883  2.8937  12.99 -0.3604   \n",
       "...        ...        ...         ...         ...     ...    ...     ...   \n",
       "3995  gdb_3996    3.33117    1.516440    1.358690  1.0785  68.31 -0.2459   \n",
       "3996  gdb_3997    3.21675    1.545420    1.343710  0.9421  68.25 -0.2486   \n",
       "3997  gdb_3998    3.70487    1.351230    0.996100  0.6382  70.97 -0.2459   \n",
       "3998  gdb_3999    3.70937    1.364910    1.003890  4.0964  65.92 -0.2614   \n",
       "3999  gdb_4000    3.32752    1.320310    1.010600  2.3826  66.14 -0.2489   \n",
       "\n",
       "        lumo     gap         r2      zpve          u0        u298        h298  \\\n",
       "0     0.1171  0.5048    35.3641  0.044749  -40.478930  -40.476062  -40.475117   \n",
       "1     0.0829  0.3399    26.1563  0.034358  -56.525887  -56.523026  -56.522082   \n",
       "2     0.0687  0.3615    19.0002  0.021375  -76.404702  -76.401867  -76.400922   \n",
       "3     0.0506  0.3351    59.5248  0.026841  -77.308427  -77.305527  -77.304583   \n",
       "4     0.0191  0.3796    48.7476  0.016601  -93.411888  -93.409370  -93.408425   \n",
       "...      ...     ...        ...       ...         ...         ...         ...   \n",
       "3995  0.0010  0.2469   986.2809  0.139181 -400.944193 -400.935445 -400.934501   \n",
       "3996  0.0004  0.2490   983.7517  0.139515 -400.947904 -400.939105 -400.938161   \n",
       "3997 -0.0376  0.2084  1091.3741  0.091451 -361.346440 -361.337818 -361.336874   \n",
       "3998 -0.0540  0.2074  1060.7387  0.081305 -377.453740 -377.445525 -377.444580   \n",
       "3999 -0.0553  0.1935  1090.1851  0.091529 -398.527244 -398.518642 -398.517698   \n",
       "\n",
       "            g298      cv      u0_atom    u298_atom    h298_atom    g298_atom  \n",
       "0     -40.498597   6.469  -395.999595  -398.643290  -401.014647  -372.471772  \n",
       "1     -56.544961   6.316  -276.861363  -278.620271  -280.399259  -259.338802  \n",
       "2     -76.422349   6.002  -213.087624  -213.974294  -215.159658  -201.407171  \n",
       "3     -77.327429   8.574  -385.501997  -387.237686  -389.016047  -365.800724  \n",
       "4     -93.431246   6.278  -301.820534  -302.906752  -304.091489  -288.720028  \n",
       "...          ...     ...          ...          ...          ...          ...  \n",
       "3995 -400.977158  31.893 -1565.545221 -1575.164307 -1584.647850 -1452.224626  \n",
       "3996 -400.981336  32.281 -1567.873907 -1577.460990 -1586.944533 -1454.846359  \n",
       "3997 -361.379798  30.819 -1327.810927 -1333.955495 -1341.067054 -1241.734889  \n",
       "3998 -377.486899  28.613 -1246.538471 -1252.049255 -1258.567191 -1166.714934  \n",
       "3999 -398.561461  29.522 -1304.591211 -1310.747702 -1317.859261 -1218.798181  \n",
       "\n",
       "[4000 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_learned, task_transferred = 'zpve', 'h298_atom'\n",
    "y_learned = StandardScaler().fit_transform(y[[task_learned]].values).reshape(-1, y[[task_learned]].values.shape[-1])\n",
    "y_transferred = StandardScaler().fit_transform(y[[task_transferred]].values).reshape(-1, y[[task_transferred]].values.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[-2]\n",
    "F = X.shape[-1]\n",
    "S = E.shape[-1]\n",
    "n_out = y_learned.shape[-1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "es_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, \\\n",
    "X_train, X_test, \\\n",
    "E_train, E_test, \\\n",
    "y_learned_train, \\\n",
    "y_learned_test, \\\n",
    "y_transferred_train, \\\n",
    "y_transferred_test = train_test_split(A, X, E, y_learned, y_transferred, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(X_in, A_in, E_in):\n",
    "    gc1 = EdgeConditionedConv(64, activation='relu')([X_in, A_in, E_in])\n",
    "    gc2 = EdgeConditionedConv(128, activation='relu')([gc1, A_in, E_in])\n",
    "    pool = GlobalAttentionPool(256)(gc2)\n",
    "    encoder = Model(inputs=[X_in, A_in, E_in], outputs=pool)\n",
    "#     encoder.compile(loss='mse', optimizer='adam')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(pool):\n",
    "    dense = Dense(256, activation='relu')(pool)\n",
    "    output = Dense(n_out)(dense)\n",
    "    classifier = Model(inputs=pool, outputs=output)\n",
    "#     classifier.compile(loss='mse', optimizer='adam')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sohompaul/psi4conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sohompaul/psi4conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sohompaul/psi4conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(N, F))\n",
    "A_in = Input(shape=(N, N))\n",
    "E_in = Input(shape=(N, N, S))\n",
    "\n",
    "learned_encoder = create_encoder(X_in, A_in, E_in)\n",
    "transferred_encoder = create_encoder(X_in, A_in, E_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer model_1 has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `get_output_at(node_index)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-958268fde1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearned_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[0;32m--> 813\u001b[0;31m                                  \u001b[0;34m' has multiple inbound nodes, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m                                  \u001b[0;34m'hence the notion of \"layer output\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                                  \u001b[0;34m'is ill-defined. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer model_1 has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `get_output_at(node_index)` instead."
     ]
    }
   ],
   "source": [
    "learned_encoder.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_in = Input(shape=(256,))\n",
    "\n",
    "learned_classifier = create_classifier(pool_in)\n",
    "transferred_classifier = create_classifier(pool_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(encoder, classifier):\n",
    "    X_in = Input(shape=(N, F))\n",
    "    A_in = Input(shape=(N, N))\n",
    "    E_in = Input(shape=(N, N, S))\n",
    "    x = encoder([X_in, A_in, E_in])\n",
    "    output = classifier(x)\n",
    "    \n",
    "    model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sohompaul/psi4conda/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learned_model = create_model(learned_encoder, learned_classifier)\n",
    "transferred_model = create_model(transferred_encoder, transferred_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f450ad001deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                   callbacks=[es_callback])\n\u001b[0m",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/psi4conda/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             raise ValueError('An operation has `None` for gradient. '\n\u001b[0m\u001b[1;32m     92\u001b[0m                              \u001b[0;34m'Please make sure that all of your ops have a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                              \u001b[0;34m'gradient defined (i.e. are differentiable). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "learned_model.fit([X_train, A_train, E_train],\n",
    "                  y_transferred_train,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_split=0.1,\n",
    "                  epochs=epochs,\n",
    "                  callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferred_model.fit([X_train, A_train, E_train],\n",
    "                     y_transferred_train,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_split=0.1,\n",
    "                     epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
